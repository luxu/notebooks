{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling of Reviews\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "First, we load the CSV, removing empty and very small text inputs to avoid simple things as \"i like\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  10000\n",
      "0    This tremendous 100% varietal wine hails from ...\n",
      "1    Ripe aromas of fig, blackberry and cassis are ...\n",
      "2    Mac Watson honors the memory of a wine once ma...\n",
      "3    This spent 20 months in 30% new French oak, an...\n",
      "4    This is the top wine from La BÃ©gude, named aft...\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"winemag-data_first150k.csv\", nrows=10000)\n",
    "\n",
    "df = df[[\"description\"]]\n",
    "df = df[(df[\"description\"].str.strip() != \"\") & (df[\"description\"].str.len() >= 40)]\n",
    "\n",
    "print(\"Total: \", len(df[\"description\"]))\n",
    "print(df[\"description\"][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import nltk to find the english stopwords, which are helper words such as \"from\", \"the\", \"that\" that we should ignore to not compromise our result.\n",
    "\n",
    "You need to uncomment the nltk download line and download the spanish corpus first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# uncomment if you need this\n",
    "# nltk.download() \n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "print(stop_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we remove those stop words and banned words from the reviews because they would only mess with the algorithm, also we remove the accents because some reviews use it, some don't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This tremendous 100% varietal hails Oakville aged three years oak. Juicy red-cherry fruit compelling hint caramel greet palate, framed elegant, fine tannins subtle minty tone background. Balanced rewarding start finish, years ahead develop nuance. Enjoy 2022-2030.',\n",
       " 'Ripe aromas fig, blackberry cassis softened sweetened slathering oaky chocolate vanilla. This full, layered, intense cushioned palate, rich flavors chocolaty black fruits baking spices. A toasty, everlasting finish heady ideally balanced. Drink 2023.',\n",
       " 'Mac Watson honors memory made mother tremendously delicious, balanced complex botrytised white. Dark gold color, layers toasted hazelnut, pear compote orange peel flavors, reveling succulence 122 g/L residual sugar.',\n",
       " \"This spent 20 months 30% new French oak, incorporates fruit Ponzi's Aurora, Abetina Madrona vineyards, among others. Aromatic, dense toasty, deftly blends aromas flavors toast, cigar box, blackberry, black cherry, coffee graphite. Tannins polished fine sheen, frame finish loaded dark chocolate espresso. Drink 2032.\",\n",
       " 'This top La Begude, named highest point vineyard 1200 feet. It structure, density considerable acidity still calming down. With 18 months wood, developing extra richness concentration. Produced Tari family, formerly Chateau Giscours Margaux, made aging. Drink 2020.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unidecode\n",
    "\n",
    "# banned words, we don't want to cluster around those\n",
    "banned_words = ['wine']\n",
    "\n",
    "text = [\" \".join([unidecode.unidecode(word) for word in text.split(\" \")\n",
    "                  if word not in stop_words\n",
    "                  and unidecode.unidecode(word) not in banned_words\n",
    "                 ]) for text in df[\"description\"]]\n",
    "\n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we tokennize and stemmatized words so we can get their essential meaning and avoid considering different genders or verb inflections of a word as a distinct word when they are probably talking about the same thing.\n",
    "\n",
    "Those words are saved in a vocabulary for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 263552 items in vocab_frame\n",
      "              words\n",
      "this           this\n",
      "tremend  tremendous\n",
      "variet     varietal\n",
      "hail          hails\n",
      "oakvill    oakville\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens\n",
    "\n",
    "def stem(tokens):\n",
    "    return [stemmer.stem(t) for t in tokens]\n",
    "\n",
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in text:\n",
    "    allwords_tokenized = tokenize(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)\n",
    "    \n",
    "    allwords_stemmed = stem(allwords_tokenized)\n",
    "    totalvocab_stemmed.extend(allwords_stemmed)\n",
    "    \n",
    "\n",
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
    "print('there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame')\n",
    "print(vocab_frame.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Model\n",
    "\n",
    "Now, we are going to send our text to a TfidfVectorizer, where we use IDF to make the algorithm focus on the main no-so-common words. We also build ngrams, so things like \"black cherry\" can be considered a single thing instead of two.\n",
    "\n",
    "Then we send it to a Latent Dirichlet Allocation model, which should group the texts around clusters, discovering topics automatically for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 12207)\n",
      "[\"'s medium\", \"'s medium bodi\", \"'s medium full\", \"'s medium-bodi\", \"'s miner\", \"'s much\", \"'s nice\", \"'s nice balanc\", \"'s nose\", \"'s nose palat\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 38s, sys: 1.68 s, total: 5min 40s\n",
      "Wall time: 5min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    return stem(tokenize(text))\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.6, max_features=200000,\n",
    "                             min_df=5, stop_words=stop_words,\n",
    "                             use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "X = vectorizer.fit_transform(text).todense()\n",
    "print(X.shape)\n",
    "\n",
    "terms = vectorizer.get_feature_names()\n",
    "print(terms[90:100])\n",
    "\n",
    "K = 7\n",
    "model = LatentDirichletAllocation(n_components=K, max_iter=100, random_state=8)\n",
    "model.fit(X)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Here we use pyLDAvis which give us an off-the-shelf visualization for LDA. The topics with more reviews in it are the biggest circles.\n",
    "\n",
    "You can click in any of it to see which are the most relevant words for that particular topic, and you can move the relevace slider to the right to see words that are more relevant to that topic and not others.\n",
    "\n",
    "This is a great visualization because we can see 3 things:\n",
    "- The biggest topics that we have to concern about\n",
    "- Which topics have overlaps and which talks about completely distinct subjects\n",
    "- Which words are in those topics, giving us a hint of what it is about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el4619747385790967321026414\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el4619747385790967321026414_data = {\"mdsDat\": {\"x\": [0.11033618571793574, 0.22007139175766322, -0.054399533252366544, -0.15540515508212843, -0.052751773731633755, -0.03727041005448551, -0.03058070535498448], \"y\": [0.0609094716411771, -0.08360416061680795, 0.21605739923405412, -0.13444139807792344, -0.028044109870083864, -0.0172320611671428, -0.013645141143273021], \"topics\": [1, 2, 3, 4, 5, 6, 7], \"cluster\": [1, 1, 1, 1, 1, 1, 1], \"Freq\": [54.28521889485742, 16.4286427972505, 13.128428052945315, 7.992914989753216, 3.1290003268588613, 2.665469321298386, 2.3703256170363023]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\"], \"Freq\": [166.0, 64.0, 185.0, 100.0, 89.0, 183.0, 219.0, 150.0, 84.0, 53.0, 135.0, 79.0, 106.0, 69.0, 49.0, 145.0, 39.0, 41.0, 109.0, 172.0, 48.0, 144.0, 106.0, 81.0, 155.0, 51.0, 39.0, 28.0, 78.0, 44.0, 71.37056902241548, 58.36528358274136, 56.048804718773965, 51.34454646443813, 44.230375572114895, 43.904594616958896, 42.7402820330874, 41.61272758942008, 39.619147574832326, 34.58145472787444, 34.67669990817126, 33.62746887991061, 33.561308259195094, 33.57978294537805, 32.62217843471112, 31.782963223509697, 31.52380619996446, 31.05271169652641, 44.90551978130803, 30.288886235653898, 29.54447535466541, 29.213323182429306, 28.843090115229057, 28.50258569198303, 28.163923323776352, 26.124919072527486, 25.78104817025611, 53.8295054424007, 24.629279292147636, 24.445947852190848, 46.88700663212601, 38.6533423625762, 172.0498214491893, 104.53931412427261, 214.7913605543786, 70.02442653033017, 72.62442016452239, 43.593254470166855, 62.555016874667885, 47.09431616490771, 96.78620450348393, 139.25261718725767, 56.86138380451991, 143.3584638801822, 105.0050923024901, 56.756053698097844, 138.99472758196742, 85.085471371628, 112.20982027731377, 65.07266312106768, 77.60038403926082, 84.15664033037298, 92.86088506746451, 134.11011375220465, 97.09969050471152, 77.81380601019934, 61.466134858604526, 101.85464054967782, 70.02471179261457, 73.50839676107611, 68.03585190569572, 62.02468501155023, 71.22770497552088, 67.80017530860496, 63.15830449180287, 23.909743298747763, 20.697739312711345, 42.755185883894825, 13.752795534048335, 13.450576848798546, 12.392523568737053, 12.211279296191936, 10.357549653699161, 10.283648393370036, 10.044239925606117, 10.005521264847468, 9.841586719980098, 8.916569180051548, 8.722715642574588, 8.738809504673263, 8.684792975987161, 8.568916373353968, 8.475650079960792, 8.380859554302896, 7.664812092671302, 7.452061233560167, 7.378982463179642, 7.340783169093721, 7.276238633032553, 7.052605807442819, 7.013344658802815, 7.0272383906383755, 6.986477635792746, 6.745657913500165, 6.7176925611667615, 46.028586775873016, 33.79589606588627, 39.12867752859062, 12.62405660595036, 71.46714860990977, 12.104803449421857, 49.978241995825655, 56.89787210734485, 52.58296920129069, 35.38966519327066, 28.241170257200462, 49.476882885227994, 91.8943903178472, 27.25722912852407, 20.650768213023806, 19.165075289297896, 14.417458406011301, 54.311193130169656, 24.510256894409807, 58.677416593745455, 59.93303355424222, 27.65993640940295, 73.2241385966275, 33.52526712607673, 44.718055165370174, 59.55158603873199, 38.07697035281182, 32.86374769286032, 22.674968460577254, 44.48896843251366, 38.790037178590055, 30.267150924588183, 27.496653283185115, 26.428097400330163, 26.976795921424497, 25.90473339187118, 20.730202153561873, 20.090574743347027, 16.26874060203616, 15.822478629272451, 14.268422773534256, 13.549268940860046, 13.50846617482039, 12.378194276148628, 12.03643529130347, 11.702890097271913, 11.164422285370984, 11.164903511355135, 10.166555620481642, 10.165112158934047, 9.262121186140071, 9.053786256624631, 9.001371418400334, 8.711627998647188, 8.652027711745017, 8.609373272972443, 8.225572289620565, 7.7851772326061495, 7.526369416265854, 7.440556076123526, 7.3802744062571755, 7.116756656667024, 7.090957671025201, 7.077091659231471, 7.048023183674414, 7.060834158315584, 47.904120515664644, 41.52027081729205, 21.36701869676625, 15.035204653787721, 9.956972139680436, 21.024469728003908, 12.057835176168675, 22.74951289104674, 10.64231496843323, 23.597159725939775, 31.54494846671688, 12.428475973948022, 13.565789164172038, 39.94941348492237, 19.455201847428174, 23.47773905890356, 15.33966413741865, 20.956978220088956, 24.63793590018869, 45.50289403326845, 37.49989671093322, 37.45664675527074, 40.019256294673, 15.947881256305974, 30.50040102217372, 21.66867443220139, 24.139072876274806, 19.796896920105777, 21.157235562741644, 21.717967049303603, 24.04656349048419, 23.482104340571283, 22.497661022229444, 21.364978200760447, 19.648334799479247, 19.00647424606862, 28.306316591478556, 19.89067339333959, 19.780712001103034, 13.854479339279278, 12.705573768346708, 11.989363622562042, 11.836743587275839, 11.383535348365987, 11.383535348365927, 11.364807514742884, 11.364807514742884, 10.695150052768481, 9.850882779614386, 8.910198906332035, 8.527437556542976, 8.44019703917756, 8.449972551892314, 8.348807575281398, 8.252084757884937, 7.80398532343105, 20.026542140669854, 7.421710956039671, 7.343650462074995, 7.22290746393138, 17.237673566849463, 6.782370687244928, 6.646708054414446, 6.251685218812287, 6.228795942863711, 6.222114568771827, 21.132598213010546, 33.531990043557556, 49.8028212507335, 31.808461024959414, 11.701914953883454, 28.785550319945624, 23.682576867254127, 15.124089908567566, 31.201103126133066, 11.950193951172926, 25.860373671677916, 15.068414670571322, 13.37509606641636, 13.96973572524139, 21.708148465568065, 14.894340694285594, 12.596377137249904, 12.106978287728458, 13.86698523694634, 7.630506232301407, 5.441787388628733, 5.250522786559872, 4.42607377907273, 4.42607377907273, 3.883089502012029, 3.8768786349428623, 3.4627607773034708, 3.4627607773034708, 3.4627607773034708, 3.4394502698989817, 3.4162786320160494, 3.380250987317388, 3.2928139245515458, 3.2000735272782483, 3.190830923908193, 3.173107495866798, 3.154991939857324, 3.154991939857324, 3.1532193188772766, 3.103871824138448, 3.1189178306256693, 3.0106669944182753, 2.966917492298615, 2.8750130479878786, 2.575530013339668, 2.5600107849470333, 2.5131041279720945, 2.4841350501244763, 4.736340594069595, 4.584929224997605, 5.208689935931497, 5.317708301291342, 3.8723196934705078, 3.139806435434079, 8.182291869523759, 6.073532900907943, 5.065814695503082, 4.993429575951545, 4.327720155830575, 4.296599968207683, 4.176333967346833, 4.05750737797321, 3.398713104204901, 3.3068759266706294, 3.3062967721805925, 3.2040256213739795, 3.2040256213739795, 3.1195814099428394, 3.1122300205891316, 2.93082348523996, 2.6931945100747074, 2.549375333938729, 2.5054444421980473, 2.4053378637881333, 2.3863269548468, 2.3375215906504225, 2.226538909536731, 2.112026247677443, 2.030872910512709, 1.998269004639615, 1.9579454096934568, 1.9509789797732617, 1.854710839789768, 1.8600392179420036, 5.7989098053938415, 2.039041835817877, 5.606669909281592, 5.370509418452785, 2.8381573481816798, 2.6825250407236476, 2.6028849408826966, 2.553352474774718, 2.4737783172346512, 2.4737783172346512, 2.3898404329296468, 1.850682494160387, 1.8097659070428693, 1.67896114158076, 1.666258205017214, 1.6406206067451652, 1.558927759750596, 1.5220584667161514, 1.5046207238764462, 1.5046207238764462, 1.4560303069971392, 1.4462678855444637, 1.4147735293395258, 1.354610235684508, 1.3347381811895174, 1.3320918949043334, 1.3385794976551812, 1.3237077585138888, 1.3208742786111505, 1.2949369414695948, 1.2433854005051694, 1.2182288452399168, 1.4022967713295167], \"Term\": [\"drink\", \"cabernet\", \"palat\", \"fruiti\", \"blend\", \"aroma\", \"fruit\", \"cherri\", \"age\", \"alongsid\", \"wine\", \"blackberri\", \"offer\", \"charact\", \"sauvignon\", \"ripe\", \"cabernet sauvignon\", \"merlot\", \"rich\", \"acid\", \"palat offer\", \"black\", \"textur\", \"structur\", \"tannin\", \"readi\", \"syrah\", \"riesl\", \"give\", \"readi drink\", \"peach\", \"tart\", \"bodi\", \"slight\", \"clean\", \"pinot\", \"bit\", \"melon\", \"linger\", \"yet\", \"floral\", \"stone\", \"mix\", \"smoke\", \"medium\", \"flavor finish\", \"seem\", \"quit\", \"color\", \"delic\", \"mouthfeel\", \"tone\", \"nice\", \"oaki\", \"barrel\", \"peel\", \"noir\", \"tast\", \"pinot noir\", \"first\", \"lime\", \"cranberri\", \"finish\", \"appl\", \"flavor\", \"pear\", \"lemon\", \"orang\", \"feel\", \"bottl\", \"nose\", \"'s\", \"sweet\", \"aroma\", \"note\", \"green\", \"palat\", \"oak\", \"cherri\", \"citrus\", \"show\", \"light\", \"dri\", \"fruit\", \"fresh\", \"plum\", \"raspberri\", \"acid\", \"spice\", \"wine\", \"red\", \"white\", \"ripe\", \"black\", \"offer\", \"age drink\", \"wood age\", \"readi drink\", \"need age\", \"yellow fruit\", \"aftertast drink\", \"drunk\", \"wine drink\", \"chateau\", \"need age drink\", \"miner textur\", \"wood-ag\", \"fruit give\", \"red berri fruit\", \"aperitif\", \"currant fruit\", \"charact 's\", \"ripe full\", \"full mouth\", \"age well\", \"light textur\", \"ripe wine\", \"fruiti crisp\", \"dri core\", \"futur\", \"cru\", \"'s readi\", \"attract acid\", \"dark tannin\", \"fruit balanc\", \"readi\", \"aftertast\", \"attract\", \"still young\", \"fruiti\", \"fruiti wine\", \"charact\", \"age\", \"structur\", \"wood\", \"young\", \"give\", \"drink\", \"need\", \"develop\", \"although\", \"potenti\", \"rich\", \"perfum\", \"wine\", \"ripe\", \"still\", \"fruit\", \"well\", \"textur\", \"acid\", \"crisp\", \"full\", \"great\", \"tannin\", \"fresh\", \"juici\", \"firm\", \"soft\", \"light\", \"red\", \"lead nose\", \"open aroma\", \"dri black\", \"dri black cherri\", \"offer dri\", \"underbrush\", \"dole\", \"palat offer dri\", \"palat dole\", \"blue flower\", \"scorch\", \"assert\", \"offer dri black\", \"wild cherri\", \"tannin leav\", \"firm palat\", \"grill herb\", \"orchard\", \"scorch earth\", \"orchard fruit\", \"balsam note\", \"aroma recal\", \"aroma lead nose\", \"offer ripe\", \"lead way\", \"note alongsid\", \"ground pepper\", \"spring flower\", \"linear palat\", \"astring finish\", \"alongsid\", \"palat offer\", \"palat deliv\", \"menthol\", \"polish tannin\", \"espresso\", \"fine-grain tannin\", \"whiff\", \"balsam\", \"flower\", \"black cherri\", \"fine-grain\", \"tannin drink\", \"offer\", \"matur\", \"licoric\", \"sage\", \"deliv\", \"open\", \"palat\", \"cherri\", \"tannin\", \"aroma\", \"anis\", \"black\", \"toast\", \"berri\", \"lead\", \"pepper\", \"white\", \"note\", \"dri\", \"red\", \"spice\", \"herb\", \"firm\", \"petit\", \"verdot\", \"petit verdot\", \"blend cabernet\", \"merlot cabernet\", \"stew\", \"blend cabernet sauvignon\", \"sirah\", \"petit sirah\", \"sauvignon merlot\", \"cabernet sauvignon merlot\", \"coffe bean\", \"roast coffe\", \"roast coffe bean\", \"aroma black\", \"milk\", \"sticki\", \"milk chocol\", \"gritti\", \"blend syrah\", \"cabernet franc\", \"merlot cabernet franc\", \"blend merlot\", \"blackberri cassi\", \"prune\", \"chocol flavor\", \"merlot cabernet sauvignon\", \"grenach syrah\", \"syrupi\", \"plum blackberri\", \"franc\", \"cabernet sauvignon\", \"cabernet\", \"merlot\", \"bean\", \"sauvignon\", \"syrah\", \"malbec\", \"blend\", \"raisin\", \"blackberri\", \"cassi\", \"roast\", \"coffe\", \"black\", \"plum\", \"chocol\", \"tannin\", \"rubberi\", \"flavor black\", \"raspberri aroma\", \"sauci\", \"bartlett pear\", \"bartlett\", \"flavor black cherri\", \"ripe cherri\", \"granni\", \"granni smith\", \"smith\", \"lactic\", \"plum currant\", \"plum flavor finish\", \"blocki\", \"plum cherri flavor\", \"flavor carri\", \"palat soft\", \"granni smith appl\", \"smith appl\", \"distract\", \"spent month\", \"dole juici\", \"light miner\", \"aroma round\", \"palat dole juici\", \"raspberri plum flavor\", \"spice tomato\", \"resini oak\", \"pear white\", \"alongsid bright\", \"alongsid bright acid\", \"plum raspberri\", \"resini\", \"grabbi\", \"raspberri plum\", \"off-dri riesl\", \"riesl 's\", \"moder long\", \"appl pear flavor\", \"cider\", \"tangerin flavor\", \"press appl\", \"tangerin acid\", \"lemon-lim acid\", \"vivaci\", \"uncompl\", \"medium-\", \"medium- full-bodi\", \"riesl palat\", \"press appl pear\", \"lend savori\", \"finish moder\", \"finish moder long\", \"fresh green\", \"lanolin\", \"moder long finish\", \"concentr flavor\", \"quench\", \"smack\", \"note lend\", \"meringu\", \"off-dri riesl 's\", \"honeycomb\", \"delic sweet\", \"blue-fruit flavor\", \"riesl\", \"off-dri\", \"fruiti readi\", \"fruiti readi drink\", \"crisp citrus\", \"plum black cherri\", \"verd\", \"common\", \"vinho verd\", \"vinho\", \"soft light\", \"miner element\", \"fruit spice flavor\", \"leather flavor\", \"acid round\", \"show bright\", \"currant berri\", \"delici alreadi\", \"atlas\", \"atlas peak\", \"alvarinho\", \"hint apricot\", \"grapefruit orang\", \"black plum black\", \"sweet tannin\", \"intermingl\", \"dark berri fruit\", \"lake\", \"much better\", \"ripe berri flavor\", \"plum wild\", \"proportion\", \"plum black\"], \"Total\": [166.0, 64.0, 185.0, 100.0, 89.0, 183.0, 219.0, 150.0, 84.0, 53.0, 135.0, 79.0, 106.0, 69.0, 49.0, 145.0, 39.0, 41.0, 109.0, 172.0, 48.0, 144.0, 106.0, 81.0, 155.0, 51.0, 39.0, 28.0, 78.0, 44.0, 72.0342760309828, 59.02574470916707, 56.709316112486526, 52.01040110087746, 44.8909145165033, 44.56512923796884, 43.40852116274112, 42.273152406470224, 40.279442176048505, 35.24204714639373, 35.34060729476218, 34.28789060897812, 34.22228738670451, 34.24239289074089, 33.2825826650773, 32.44352718745727, 32.186965869171146, 31.719306581394193, 45.88525784726583, 30.951374794368757, 30.204690456429336, 29.88194381512888, 29.504155983337217, 29.163001964871125, 28.82467868882529, 26.787608099152962, 26.441749391602706, 55.22696074444795, 25.290017383014792, 25.10909817883733, 48.221215447690845, 39.844407582144235, 181.9737099029919, 111.3423010336458, 237.222212521443, 74.02174911859171, 78.51823933164954, 45.62210183626258, 67.38011874376069, 49.80607723475348, 110.01161744912122, 165.1377244450536, 61.55799199745655, 183.94672001248168, 129.59147926714422, 63.49214260335891, 185.03772628245082, 103.88913541017995, 150.24975260412512, 77.52710219638274, 99.83206682263953, 111.67781922915204, 130.41981868256755, 219.27651205100392, 142.34081963625545, 107.10338822509476, 75.26049261876274, 172.7936760703025, 106.89848671854816, 135.47174134074334, 116.86109607968112, 86.91870053837197, 145.56609746735825, 144.2976834197246, 106.21366942885798, 24.57525797694347, 21.360063579114648, 44.136092542126285, 14.415122571953052, 14.113594482191013, 13.054921505865014, 12.874643138648924, 11.021608982272369, 10.946294648595108, 10.70656423751644, 10.667857461734654, 10.503974834290458, 9.580150447797314, 9.386626145935873, 9.406243142707964, 9.348358111731152, 9.23329088306941, 9.138360868990091, 9.043777685122986, 8.329966448367212, 8.115695172815586, 8.041831447811312, 8.003272245367885, 7.938543328083351, 7.716923163315447, 7.6756941471697235, 7.692170669025788, 7.6490764141159255, 7.408004957032533, 7.38128646048046, 51.20332002157221, 37.576278271096434, 46.12925141242616, 14.630158066352232, 100.28654285812722, 14.143157692552146, 69.79782216135415, 84.28061767707514, 81.99763615969518, 51.21293534475307, 39.735182779234165, 78.18264538094498, 166.75008429711932, 39.30111580748458, 27.895846430294693, 25.494810788316617, 18.0999563708487, 109.150143984656, 38.56593557005805, 135.47174134074334, 145.56609746735825, 48.75496462088659, 219.27651205100392, 66.39642335236066, 106.29120026972444, 172.7936760703025, 89.67945751525313, 72.67423273487793, 38.22063308083086, 155.36220046704415, 142.34081963625545, 85.59707448262458, 69.39465638564295, 89.2385447706635, 111.67781922915204, 116.86109607968112, 21.390043805340305, 20.75016379342289, 16.927752225042823, 16.48120053630263, 14.927550120641953, 14.208382221729153, 14.16731316344286, 13.03671020605555, 12.695142427930763, 12.361408438910816, 11.823093501890744, 11.826536463668747, 10.825079104486104, 10.8247510764893, 9.921154102409451, 9.713835157733556, 9.66083738137314, 9.37072789219162, 9.310627570619879, 9.268064889601494, 8.884155911812215, 8.444451496822747, 8.185304429886255, 8.101328261990135, 8.042167680287005, 7.775947817036645, 7.749481770608039, 7.736204446751538, 7.706763238366141, 7.721106966894015, 53.504259861001046, 48.36956492125448, 24.513562877329555, 17.979310633246786, 11.323932007728125, 30.50574491698506, 15.145656752050007, 34.98420612383279, 12.90205021163665, 41.3301964934571, 66.87272601079557, 16.308746735874056, 18.827356682890446, 106.21366942885798, 33.805727183090774, 46.15002461519352, 23.020411918283298, 38.65617566805762, 56.96595415673741, 185.03772628245082, 150.24975260412512, 155.36220046704415, 183.94672001248168, 27.098739286037056, 144.2976834197246, 61.15355911198823, 102.32423444121956, 57.36971957647483, 72.79600598689669, 86.91870053837197, 129.59147926714422, 130.41981868256755, 116.86109607968112, 106.89848671854816, 74.59944266122365, 69.39465638564295, 28.970507470656678, 20.554753517700487, 20.444584872788514, 14.518292936253864, 13.369600999059607, 12.654897039110626, 12.500487934122813, 12.047405151007608, 12.047405151007615, 12.028681739504725, 12.028681739504725, 11.360393039115499, 10.51644920441866, 9.575014480620656, 9.193357094879707, 9.10489063223447, 9.116385009027201, 9.013206180722385, 8.919013419941546, 8.468380306472346, 21.789767357992588, 8.085569092567283, 8.007583260740201, 7.886926362931607, 18.89404169462191, 7.447811806911711, 7.310960282844156, 6.915682814580716, 6.893900194206308, 6.887920545394512, 24.384669779747988, 39.91542035208498, 64.07630922778284, 41.161353674744966, 14.78072824701448, 49.513443933136145, 39.08080605149328, 23.01615067926202, 89.96389262429838, 17.635494339627286, 79.45958244771211, 30.93552194303219, 28.196454550572053, 36.20158179356438, 144.2976834197246, 107.10338822509476, 49.37773938278471, 155.36220046704415, 14.544813123040623, 8.309672322498662, 6.11802120016538, 5.928293767603714, 5.102321692694172, 5.102321692694172, 4.559321936847782, 4.556724167052588, 4.138044015744223, 4.138044015744223, 4.138044015744223, 4.116495653155004, 4.092761291936884, 4.056762100168286, 3.9720149964790363, 3.8787070837730226, 3.869467670077813, 3.852012906898206, 3.8300839488608407, 3.8300839488608407, 3.832276784078907, 3.7819979265902957, 3.801125786746049, 3.6946976103192473, 3.6468755276621097, 3.553963339870733, 3.250594156655641, 3.23854541642302, 3.1913352256606546, 3.1626329835309552, 6.348224659869402, 6.149869881482971, 7.388877225284466, 10.214054695381082, 10.130513974373246, 6.462413189962584, 8.860038562291011, 6.75114031811969, 5.74310360857894, 5.674834387639338, 5.007506364006105, 4.97585405868006, 4.853810767956348, 4.734993189487411, 4.076534244826451, 3.984852580187751, 3.984844323567946, 3.881607551039621, 3.881607551039621, 3.797894756337896, 3.7894339181318886, 3.6083456358877757, 3.370487965596987, 3.226496253772197, 3.1847063749298865, 3.0843952445974487, 3.0636399983974734, 3.016760575710722, 2.906703214248939, 2.7916902394060386, 2.7085562483486867, 2.675674658260229, 2.635084631704832, 2.628709130516231, 2.5323408069775173, 2.540824150897256, 28.808307227789566, 21.00528493512439, 6.287325240339261, 6.0510928366456875, 3.520647084948413, 3.365527462966284, 3.2824418694149147, 3.237439582777781, 3.1531149734731314, 3.1531149734731314, 3.0731014614504106, 2.5341044945713667, 2.491583557417408, 2.3602056855065308, 2.3554507204190824, 2.321648457951926, 2.239809224931593, 2.206860988952788, 2.1849549400671844, 2.1849549400671844, 2.137556510986619, 2.132114926346312, 2.0955935142609077, 2.04003708344204, 2.017548344786542, 2.013628066275005, 2.02385942293869, 2.008257961315724, 2.0054325713087535, 1.9813563345836243, 1.9277617243589125, 1.900379967238937, 6.108478283187748], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6017, 0.5997, 0.5992, 0.598, 0.5961, 0.596, 0.5954, 0.5952, 0.5944, 0.592, 0.592, 0.5915, 0.5914, 0.5914, 0.5909, 0.5903, 0.5901, 0.5897, 0.5893, 0.5893, 0.5888, 0.5883, 0.5883, 0.588, 0.5877, 0.5859, 0.5856, 0.5853, 0.5844, 0.5842, 0.5829, 0.5806, 0.5548, 0.5479, 0.5116, 0.5554, 0.5329, 0.5654, 0.5366, 0.5549, 0.4828, 0.4404, 0.5316, 0.3616, 0.4005, 0.4988, 0.3248, 0.4113, 0.319, 0.4358, 0.359, 0.328, 0.2713, 0.1192, 0.2284, 0.2914, 0.4084, 0.0824, 0.1879, -0.0004, 0.07, 0.2735, -0.1038, -0.1444, 0.0911, 1.7787, 1.7746, 1.7744, 1.7591, 1.758, 1.7541, 1.7532, 1.744, 1.7437, 1.7423, 1.742, 1.741, 1.7344, 1.7328, 1.7325, 1.7325, 1.7315, 1.7309, 1.73, 1.7229, 1.7208, 1.7201, 1.7197, 1.719, 1.7161, 1.7159, 1.7157, 1.7155, 1.7125, 1.7119, 1.6996, 1.7001, 1.6416, 1.6587, 1.4674, 1.6505, 1.4721, 1.4132, 1.3618, 1.4366, 1.4647, 1.3486, 1.2103, 1.4402, 1.5054, 1.5208, 1.5787, 1.1081, 1.3529, 0.9694, 0.9187, 1.2393, 0.7093, 1.1228, 0.9403, 0.7409, 0.9495, 1.0125, 1.284, 0.5556, 0.5061, 0.7666, 0.8804, 0.5893, 0.3855, 0.2996, 1.9991, 1.9981, 1.9907, 1.9896, 1.9852, 1.9829, 1.9828, 1.9786, 1.9771, 1.9756, 1.9731, 1.9728, 1.9676, 1.9675, 1.9617, 1.96, 1.9597, 1.9575, 1.957, 1.9567, 1.9534, 1.9491, 1.9465, 1.9453, 1.9445, 1.9418, 1.9416, 1.9413, 1.941, 1.941, 1.9198, 1.8777, 1.893, 1.8516, 1.9017, 1.6582, 1.8024, 1.6, 1.8378, 1.4699, 1.279, 1.7587, 1.7026, 1.0526, 1.4779, 1.3545, 1.6245, 1.4182, 1.1922, 0.6276, 0.6424, 0.6078, 0.5051, 1.5002, 0.4763, 0.9929, 0.5861, 0.9664, 0.7947, 0.6436, 0.346, 0.3159, 0.3828, 0.4203, 0.6962, 0.7354, 2.5034, 2.4938, 2.4936, 2.4798, 2.4757, 2.4726, 2.4721, 2.4699, 2.4699, 2.4698, 2.4698, 2.4663, 2.4612, 2.4547, 2.4514, 2.4508, 2.4507, 2.45, 2.4489, 2.4449, 2.4422, 2.4409, 2.4401, 2.4387, 2.4349, 2.433, 2.4314, 2.4257, 2.4252, 2.425, 2.3835, 2.3524, 2.2746, 2.2688, 2.293, 1.9842, 2.0257, 2.1067, 1.4677, 2.1374, 1.4041, 1.8073, 1.7808, 1.5744, 0.6324, 0.5538, 1.1605, -0.0254, 3.4167, 3.3792, 3.3473, 3.343, 3.3223, 3.3223, 3.3039, 3.3029, 3.2863, 3.2863, 3.2863, 3.2848, 3.2838, 3.282, 3.2769, 3.2721, 3.2716, 3.2706, 3.2706, 3.2706, 3.2694, 3.2669, 3.2666, 3.2597, 3.2581, 3.2525, 3.2317, 3.2293, 3.2255, 3.223, 3.1715, 3.1708, 3.1148, 2.8117, 2.5028, 2.7426, 3.5452, 3.519, 3.4993, 3.4969, 3.4789, 3.478, 3.4745, 3.4704, 3.4429, 3.4383, 3.4381, 3.4329, 3.4329, 3.428, 3.4279, 3.4168, 3.4005, 3.3892, 3.3849, 3.3761, 3.3749, 3.3697, 3.3582, 3.3458, 3.3368, 3.3329, 3.3278, 3.3266, 3.3134, 3.3129, 2.0218, 1.2925, 3.6276, 3.6228, 3.5267, 3.5153, 3.5102, 3.5048, 3.4995, 3.4995, 3.4907, 3.4279, 3.4224, 3.4016, 3.396, 3.3949, 3.3798, 3.3706, 3.3691, 3.3691, 3.3582, 3.354, 3.3493, 3.3327, 3.329, 3.329, 3.3287, 3.3253, 3.3246, 3.3168, 3.3036, 3.2975, 2.2706], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.0357, -6.2369, -6.2774, -6.365, -6.5142, -6.5216, -6.5485, -6.5752, -6.6243, -6.7603, -6.7575, -6.7883, -6.7902, -6.7897, -6.8186, -6.8447, -6.8529, -6.8679, -6.499, -6.8928, -6.9177, -6.929, -6.9417, -6.9536, -6.9656, -7.0407, -7.054, -6.3178, -7.0997, -7.1071, -6.4559, -6.649, -5.1558, -5.654, -4.9339, -6.0548, -6.0183, -6.5287, -6.1676, -6.4514, -5.7311, -5.3673, -6.263, -5.3383, -5.6496, -6.2648, -5.3692, -5.8599, -5.5832, -6.1281, -5.952, -5.8709, -5.7725, -5.4049, -5.7279, -5.9493, -6.1851, -5.6801, -6.0548, -6.0062, -6.0836, -6.1761, -6.0377, -6.087, -6.158, -5.9341, -6.0784, -5.3529, -6.4871, -6.5094, -6.5913, -6.606, -6.7707, -6.7778, -6.8014, -6.8052, -6.8218, -6.9205, -6.9424, -6.9406, -6.9468, -6.9602, -6.9712, -6.9824, -7.0717, -7.0999, -7.1097, -7.1149, -7.1238, -7.155, -7.1606, -7.1586, -7.1644, -7.1995, -7.2036, -5.2791, -5.588, -5.4415, -6.5728, -4.8391, -6.6148, -5.1968, -5.0671, -5.146, -5.542, -5.7676, -5.2069, -4.5877, -5.8031, -6.0806, -6.1553, -6.4399, -5.1136, -5.9093, -5.0363, -5.0151, -5.7884, -4.8149, -5.5961, -5.308, -5.0215, -5.4688, -5.616, -5.9871, -5.3131, -5.4502, -5.6983, -5.7943, -5.8339, -5.8134, -5.8539, -5.8525, -5.8839, -6.0949, -6.1227, -6.2261, -6.2778, -6.2808, -6.3682, -6.3962, -6.4243, -6.4714, -6.4714, -6.565, -6.5652, -6.6582, -6.6809, -6.6868, -6.7195, -6.7263, -6.7313, -6.7769, -6.8319, -6.8657, -6.8772, -6.8853, -6.9217, -6.9253, -6.9273, -6.9314, -6.9296, -5.0149, -5.1579, -5.8223, -6.1737, -6.5859, -5.8384, -6.3944, -5.7596, -6.5193, -5.723, -5.4327, -6.3641, -6.2766, -5.1965, -5.916, -5.7281, -6.1537, -5.8417, -5.6798, -5.0664, -5.2598, -5.2609, -5.1948, -6.1148, -5.4664, -5.8083, -5.7003, -5.8986, -5.8321, -5.806, -5.7041, -5.7279, -5.7707, -5.8224, -5.9061, -5.9393, -5.0448, -5.3977, -5.4032, -5.7593, -5.8459, -5.9039, -5.9167, -5.9557, -5.9557, -5.9574, -5.9574, -6.0181, -6.1003, -6.2007, -6.2446, -6.2549, -6.2537, -6.2658, -6.2774, -6.3333, -5.3908, -6.3835, -6.3941, -6.4106, -5.5408, -6.4736, -6.4938, -6.5551, -6.5587, -6.5598, -5.3371, -4.8754, -4.4798, -4.9282, -5.9282, -5.028, -5.2232, -5.6716, -4.9475, -5.9072, -5.1352, -5.6753, -5.7945, -5.751, -5.3102, -5.6869, -5.8545, -5.8941, -4.8206, -5.4179, -5.756, -5.7917, -5.9625, -5.9625, -6.0934, -6.095, -6.208, -6.208, -6.208, -6.2148, -6.2215, -6.2321, -6.2583, -6.2869, -6.2898, -6.2954, -6.3011, -6.3011, -6.3016, -6.3174, -6.3126, -6.3479, -6.3625, -6.394, -6.504, -6.5101, -6.5285, -6.5401, -5.8948, -5.9273, -5.7997, -5.779, -6.0962, -6.3059, -5.1878, -5.4858, -5.6672, -5.6816, -5.8247, -5.8319, -5.8603, -5.8892, -6.0663, -6.0937, -6.0939, -6.1253, -6.1253, -6.152, -6.1544, -6.2144, -6.299, -6.3539, -6.3713, -6.412, -6.42, -6.4406, -6.4893, -6.5421, -6.5813, -6.5974, -6.6178, -6.6214, -6.672, -6.6691, -5.5321, -6.5772, -5.4484, -5.4915, -6.1292, -6.1856, -6.2158, -6.235, -6.2666, -6.2666, -6.3012, -6.5568, -6.5792, -6.6542, -6.6618, -6.6773, -6.7284, -6.7523, -6.7638, -6.7638, -6.7967, -6.8034, -6.8254, -6.8689, -6.8836, -6.8856, -6.8808, -6.8919, -6.8941, -6.9139, -6.9545, -6.975, -6.8343]}, \"token.table\": {\"Topic\": [1, 2, 4, 2, 1, 2, 3, 7, 1, 2, 2, 1, 2, 2, 2, 1, 3, 4, 5, 4, 5, 1, 2, 7, 1, 3, 2, 1, 2, 6, 1, 3, 4, 3, 3, 5, 3, 3, 7, 7, 1, 2, 2, 3, 4, 3, 1, 5, 5, 1, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 3, 4, 7, 1, 2, 3, 4, 4, 1, 2, 4, 4, 4, 4, 4, 5, 3, 6, 1, 1, 2, 1, 2, 4, 2, 4, 1, 2, 4, 4, 1, 4, 1, 2, 2, 2, 1, 3, 1, 2, 4, 4, 6, 1, 2, 1, 1, 3, 4, 4, 1, 7, 6, 1, 3, 1, 2, 7, 2, 7, 2, 7, 2, 1, 6, 7, 1, 3, 1, 2, 3, 5, 3, 5, 1, 2, 3, 3, 3, 2, 1, 2, 3, 2, 1, 3, 4, 1, 2, 4, 1, 3, 1, 3, 1, 3, 6, 6, 1, 2, 3, 3, 1, 1, 2, 4, 5, 5, 5, 1, 1, 1, 3, 2, 4, 1, 2, 3, 6, 1, 2, 3, 2, 2, 7, 1, 2, 2, 7, 7, 1, 2, 1, 2, 2, 2, 1, 2, 3, 4, 5, 5, 5, 5, 7, 1, 2, 1, 2, 3, 4, 3, 4, 3, 1, 3, 7, 6, 7, 1, 2, 3, 5, 7, 6, 1, 3, 3, 3, 7, 1, 2, 6, 6, 1, 2, 3, 4, 1, 2, 5, 2, 1, 2, 3, 1, 1, 2, 4, 1, 2, 3, 1, 6, 6, 1, 3, 4, 6, 1, 2, 4, 4, 4, 4, 4, 4, 7, 2, 1, 6, 6, 1, 7, 1, 2, 3, 2, 2, 1, 1, 1, 3, 1, 3, 3, 6, 1, 3, 4, 1, 1, 6, 6, 6, 1, 2, 3, 3, 3, 3, 1, 2, 3, 3, 1, 3, 3, 3, 1, 3, 1, 3, 3, 5, 1, 3, 3, 5, 1, 1, 2, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 4, 4, 1, 1, 1, 2, 3, 4, 3, 4, 7, 7, 4, 5, 5, 5, 4, 5, 7, 3, 4, 1, 2, 6, 6, 7, 1, 4, 6, 1, 1, 3, 4, 1, 3, 5, 1, 5, 5, 1, 2, 1, 2, 1, 2, 3, 2, 4, 5, 5, 1, 2, 3, 1, 6, 6, 6, 1, 2, 3, 7, 5, 2, 2, 1, 4, 4, 4, 5, 1, 3, 5, 1, 2, 4, 4, 3, 3, 1, 1, 2, 3, 7, 4, 1, 6, 5, 5, 1, 1, 2, 4, 7, 5, 1, 2, 3, 5, 3, 4, 4, 1, 2, 3, 1, 2, 1, 1, 2, 3, 1, 2, 7, 1, 4, 4, 6, 6, 1, 2, 3, 4, 1, 2, 3, 3, 1, 1, 2, 1, 2, 1, 2, 3, 1, 6, 3, 7, 4, 7, 7, 6, 1, 2, 1, 3, 1, 2, 3, 3, 1, 2, 3, 2, 1, 2, 3, 2, 2, 2, 1, 1, 2], \"Freq\": [0.8417216627340022, 0.13322213367012983, 0.01816665459138134, 0.910016210143001, 0.5902993808552374, 0.3472349299148455, 0.06365973715105501, 0.8490943931292094, 0.07983760335061153, 0.9048261713069307, 0.919193577273438, 0.3203583545561054, 0.6763120818406669, 0.976591986237411, 0.9603880219191171, 0.09345050306255095, 0.8971248294004891, 0.15752435579691226, 0.7876217789845613, 0.1626050663300963, 0.8130253316504815, 0.23534200939234234, 0.7452496964090841, 0.4678238890341365, 0.40592294290487085, 0.5904333714979939, 0.9568113287585067, 0.9430378124507302, 0.05388787499718458, 0.8810829811863354, 0.7773990207071741, 0.21745427152648228, 0.9789677380216855, 0.9773613270619881, 0.9473676298584965, 0.8226219889449312, 0.9301117054677948, 0.9066057535550377, 0.915350684503591, 0.915350684503591, 0.13006931212379783, 0.845450528804686, 0.9151431651384613, 0.852577677156988, 0.15501412311945234, 0.9004794692271602, 0.9713898393203946, 0.7839568417897785, 0.7839568417897785, 0.20296699525654036, 0.8118679810261614, 0.5277342195120008, 0.15636569467022246, 0.2345485420053337, 0.07818284733511123, 0.9905889177562731, 0.47124803661750836, 0.16632283645323823, 0.2148336637520994, 0.15246260008213505, 0.5084285033409768, 0.4785209443209193, 0.014953779510028728, 0.49018716773165527, 0.5663256540469738, 0.07551008720626318, 0.02517002906875439, 0.3272103778938071, 0.8875447389619177, 0.48908510644098147, 0.15561798841303956, 0.3445826886288733, 0.9643006971598137, 0.9599625281220726, 0.8741713663246927, 0.9446906858783415, 0.7552841574514014, 0.9707631666167436, 0.7871461703848054, 0.9874920707722951, 0.9436599429116359, 0.040155742251558976, 0.12485113603470907, 0.09363835202603181, 0.7803196002169317, 0.045893101269536746, 0.9178620253907349, 0.05010594858724894, 0.10021189717449788, 0.851801125983232, 0.9144809246946557, 0.48487948668273717, 0.48487948668273717, 0.27221479713331187, 0.7163547292981892, 0.9747337232170187, 0.9135511441109837, 0.7454255202342678, 0.24625664507739203, 0.7088214332510039, 0.020252040950028683, 0.2632765323503729, 0.9398733724050152, 0.7988007821122209, 0.8384164783477844, 0.1547845806180525, 0.980153790001855, 0.2762310237443193, 0.3314772284931832, 0.38672343324204705, 0.9682763582320952, 0.9807071401840542, 0.9266582196495993, 0.6629627873364852, 0.9788073751528773, 0.02509762500391993, 0.5686921109143157, 0.42373137675968625, 0.8521160819628014, 0.9119696363332984, 0.8929331916922892, 0.9627359042553151, 0.49410546437458447, 0.9449237737556847, 0.9692622766940275, 0.7897831107445232, 0.9062646038929036, 0.4397744915580835, 0.5432508425129267, 0.21508578400704279, 0.7528002440246497, 0.03584763066784046, 0.7828244589387231, 0.9881901979921929, 0.789239864268777, 0.7130818071933936, 0.10734564839470442, 0.17635356521987156, 0.9451934189070708, 0.9708030652716891, 0.8817738608589356, 0.3418289126525179, 0.5517238590180991, 0.10194897394899657, 0.9320646693481316, 0.2294649751726772, 0.6883949255180316, 0.06556142147790776, 0.9349938999006843, 0.02968234602859315, 0.02968234602859315, 0.1839503702268522, 0.7358014809074088, 0.19807658717697676, 0.7923063487079071, 0.9451914789872187, 0.049457693667935856, 0.8900788344659271, 0.9298011725544719, 0.3170272920978333, 0.3890789493927954, 0.27379629772085606, 0.9265135606954125, 0.9558288326033108, 0.9063232220741796, 0.08852459378398964, 0.004215456846856649, 0.9627335097606418, 0.8773234387492089, 0.7753004433138658, 0.9863292549883805, 0.99036215501558, 0.4113215383016927, 0.5806892305435661, 0.12302811672650031, 0.8611968170855021, 0.6814629861474625, 0.2739902727809385, 0.042152349658605925, 0.9420020707767909, 0.6111005631502907, 0.3329129933579942, 0.05472542356569767, 0.9483441724526104, 0.9394424491600022, 0.8027023593272756, 0.2791999724191398, 0.7079713586342473, 0.8746422444958615, 0.9543008784569005, 0.8262970235260279, 0.07070556814385268, 0.8484668177262322, 0.5366413724968445, 0.4540811613434838, 0.8845860964893022, 0.9070972785211155, 0.2813923715781807, 0.6267375548786751, 0.07674337406677655, 0.5922700482105804, 0.39484669880705353, 0.7249802052819521, 0.7249802052819521, 0.7832726488651175, 0.4771917803690516, 0.3924581774529289, 0.6017692054278243, 0.8977488814022878, 0.0472499411264362, 0.06299992150191493, 0.867593289175997, 0.9315962627994042, 0.8969601931658974, 0.903286207672538, 0.7238659978363201, 0.2680985177171556, 0.46901786936675355, 0.760829707928635, 0.4966160418343256, 0.4556230482843972, 0.35047926791107475, 0.18692227621923987, 0.7287752138644216, 0.4979439988600086, 0.6484253285966353, 0.6449395303506471, 0.3486159623517011, 0.9817651703339231, 0.8704120926449258, 0.8473837734912387, 0.9297202869215991, 0.06367947170695884, 0.7359192440998905, 0.8314059413163446, 0.32502691222967833, 0.021668460815311888, 0.49837459875217344, 0.13001076489187133, 0.7521636846045513, 0.24176689862289147, 0.811974433745548, 0.8625262347761988, 0.9746747269567357, 0.020737760148015653, 0.9082931165125585, 0.9930624119662047, 0.1303432551257607, 0.17379100683434762, 0.6517162756288035, 0.23664629240697138, 0.17748471930522852, 0.562034944466557, 0.9915095932331656, 0.7728756605485535, 0.7728756605485535, 0.9935383951534115, 0.834292276605003, 0.11123897021400041, 0.7474750316992708, 0.12147316727019619, 0.09717853381615696, 0.7774282705292557, 0.9723551212122483, 0.8657399275005639, 0.9574665610516511, 0.8786486651116078, 0.8875864858290439, 0.7892334370127432, 0.9373953519598249, 0.9935046017178014, 0.8706094022979307, 0.6528182165809816, 0.9932232228393598, 0.498645536283175, 0.17811199138185554, 0.6870033953300142, 0.10177828078963175, 0.9712022863571941, 0.9340064448461817, 0.9829123739848059, 0.9832934884503899, 0.8817250600361466, 0.11816933794298873, 0.8102384554431197, 0.18519736124414163, 0.900211802433063, 0.7384007628489646, 0.8181798766964324, 0.14438468412289984, 0.02887693682457997, 0.9944106589209344, 0.8569271997782308, 0.09521413330869231, 0.9029306073281216, 0.7589889053036036, 0.5931439930356371, 0.02824495204931605, 0.37659936065754734, 0.9378632050707819, 0.923780778272172, 0.8640558404283709, 0.49152165384538576, 0.07021737912076939, 0.4388586195048087, 0.9638478134008434, 0.964444824526404, 0.021919200557418275, 0.9604376632790139, 0.971076498406668, 0.7511981626267038, 0.2485979530994847, 0.12238123095416852, 0.8566686166791796, 0.94524343213343, 0.8441280095222136, 0.12404494457967492, 0.8683146120577244, 0.9204776212963606, 0.7788135898058866, 0.985641890389265, 0.9456680074913065, 0.04052862889248456, 0.6323844753453114, 0.9705980430862782, 0.5906917476728053, 0.013737017387739657, 0.2884773651425328, 0.0961591217141776, 0.28522580451905893, 0.648240464816043, 0.051859237185283444, 0.9665001563524672, 0.9130596889638087, 0.9782541501549268, 0.9873190261616619, 0.9885323375376731, 0.7282682769668372, 0.04668386390813059, 0.08403095503463506, 0.14005159172439177, 0.16370689288562776, 0.654827571542511, 0.16370689288562776, 0.8913907353339146, 0.8710901875910568, 0.7734536110114667, 0.7330014594084135, 0.7395060212861758, 0.2706771190020689, 0.6766927975051723, 0.5187363082087105, 0.8830854859580052, 0.08830854859580052, 0.16574625587671132, 0.7734825274246528, 0.8240947558992217, 0.7916749743663394, 0.5262105564356693, 0.05292673828938594, 0.899754550919561, 0.6880647429692194, 0.9773227520107227, 0.17011147758183018, 0.11340765172122012, 0.6804459103273207, 0.8105182131746034, 0.17273338969294824, 0.8172577106899926, 0.4642228702831317, 0.4642228702831317, 0.9229081993694767, 0.09764991797198845, 0.8983792453422937, 0.022657193747850166, 0.9742593311575571, 0.5818874054855224, 0.22248636092093504, 0.18825769001002196, 0.958810957214561, 0.3916172489079041, 0.48952156113488016, 0.9400454003947375, 0.4580845995679937, 0.4947313675334332, 0.036646767965439496, 0.7636686121834323, 0.2082732578682088, 0.8887387489038451, 0.7899113041491274, 0.4877509340107235, 0.41218388789638605, 0.09617624050915675, 0.5047047734652671, 0.8778235972504143, 0.8754305191806356, 0.8704484849536532, 0.49651632530218115, 0.4610508734948825, 0.9508912947345702, 0.9399463591637949, 0.9625424459955709, 0.3040779645841373, 0.6515956383945799, 0.8434129947006757, 0.26255495411620805, 0.14137574452411203, 0.5856995130284641, 0.9144809246946557, 0.9303825600500313, 0.9666373111518198, 0.9941912552450238, 0.7813120822047477, 0.17028596663436807, 0.05008410783363767, 0.8614568640440627, 0.9130596889638093, 0.9805730953907138, 0.716411861090119, 0.7249802052819521, 0.7832726488651175, 0.9929212630812834, 0.6723552042919972, 0.2913539218598655, 0.022411840143066575, 0.6508083202225483, 0.7932315295330383, 0.65482685628939, 0.14032004063344072, 0.196448056886817, 0.9263418029547063, 0.9048364799794462, 0.9482495166032064, 0.8775408226043835, 0.3281717077309828, 0.5743004885292199, 0.0820429269327457, 0.06835196143915157, 0.8885754987089703, 0.9916037235343158, 0.28049589082307397, 0.6463600962444748, 0.07317284108428017, 0.9259561293415017, 0.06497937749764925, 0.49565107204695047, 0.3838201284854729, 0.6141122055767567, 0.8703346191525155, 0.8447741823326724, 0.8038820979932592, 0.39263089616794844, 0.28320917100638904, 0.23815316652809987, 0.07723886481992429, 0.15934260186010502, 0.10622840124007002, 0.7435988086804901, 0.9071525255125571, 0.9826220793279078, 0.977783301345778, 0.018107098173069963, 0.573895109333665, 0.42336524459040864, 0.5396251743838545, 0.09811366806979172, 0.359750116255903, 0.9704857280843168, 0.752852497212203, 0.9853338530399, 0.9139537330282534, 0.9730109379700045, 0.6342933945719764, 0.6342933945719764, 0.7528509373008353, 0.4819536713623637, 0.5120757758225114, 0.3430119282262366, 0.6574395291002868, 0.7133102498768822, 0.03451501209081688, 0.25311008866599044, 0.9238087720760056, 0.5462393800185426, 0.43551518136613526, 0.022144839730481456, 0.9073085441594264, 0.23431580164696494, 0.683421088136981, 0.058578950411741236, 0.9831431410407079, 0.952020559622323, 0.9210977413587883, 0.9931318647470087, 0.2768327520000402, 0.7046651869091932], \"Term\": [\"'s\", \"'s\", \"'s\", \"'s readi\", \"acid\", \"acid\", \"acid\", \"acid round\", \"aftertast\", \"aftertast\", \"aftertast drink\", \"age\", \"age\", \"age drink\", \"age well\", \"alongsid\", \"alongsid\", \"alongsid bright\", \"alongsid bright\", \"alongsid bright acid\", \"alongsid bright acid\", \"although\", \"although\", \"alvarinho\", \"anis\", \"anis\", \"aperitif\", \"appl\", \"appl\", \"appl pear flavor\", \"aroma\", \"aroma\", \"aroma black\", \"aroma lead nose\", \"aroma recal\", \"aroma round\", \"assert\", \"astring finish\", \"atlas\", \"atlas peak\", \"attract\", \"attract\", \"attract acid\", \"balsam\", \"balsam\", \"balsam note\", \"barrel\", \"bartlett\", \"bartlett pear\", \"bean\", \"bean\", \"berri\", \"berri\", \"berri\", \"berri\", \"bit\", \"black\", \"black\", \"black\", \"black\", \"black cherri\", \"black cherri\", \"black cherri\", \"black plum black\", \"blackberri\", \"blackberri\", \"blackberri\", \"blackberri\", \"blackberri cassi\", \"blend\", \"blend\", \"blend\", \"blend cabernet\", \"blend cabernet sauvignon\", \"blend merlot\", \"blend syrah\", \"blocki\", \"blue flower\", \"blue-fruit flavor\", \"bodi\", \"bottl\", \"bottl\", \"cabernet\", \"cabernet\", \"cabernet\", \"cabernet franc\", \"cabernet franc\", \"cabernet sauvignon\", \"cabernet sauvignon\", \"cabernet sauvignon\", \"cabernet sauvignon merlot\", \"cassi\", \"cassi\", \"charact\", \"charact\", \"charact 's\", \"chateau\", \"cherri\", \"cherri\", \"chocol\", \"chocol\", \"chocol\", \"chocol flavor\", \"cider\", \"citrus\", \"citrus\", \"clean\", \"coffe\", \"coffe\", \"coffe\", \"coffe bean\", \"color\", \"common\", \"concentr flavor\", \"cranberri\", \"cranberri\", \"crisp\", \"crisp\", \"crisp citrus\", \"cru\", \"currant berri\", \"currant fruit\", \"dark berri fruit\", \"dark tannin\", \"delic\", \"delic sweet\", \"delici alreadi\", \"deliv\", \"deliv\", \"develop\", \"develop\", \"develop\", \"distract\", \"dole\", \"dole juici\", \"dri\", \"dri\", \"dri\", \"dri black\", \"dri black cherri\", \"dri core\", \"drink\", \"drink\", \"drink\", \"drunk\", \"espresso\", \"espresso\", \"espresso\", \"feel\", \"feel\", \"feel\", \"fine-grain\", \"fine-grain\", \"fine-grain tannin\", \"fine-grain tannin\", \"finish\", \"finish\", \"finish moder\", \"finish moder long\", \"firm\", \"firm\", \"firm\", \"firm palat\", \"first\", \"flavor\", \"flavor\", \"flavor\", \"flavor black\", \"flavor black cherri\", \"flavor carri\", \"flavor finish\", \"floral\", \"flower\", \"flower\", \"franc\", \"franc\", \"fresh\", \"fresh\", \"fresh\", \"fresh green\", \"fruit\", \"fruit\", \"fruit\", \"fruit balanc\", \"fruit give\", \"fruit spice flavor\", \"fruiti\", \"fruiti\", \"fruiti crisp\", \"fruiti readi\", \"fruiti readi drink\", \"fruiti wine\", \"fruiti wine\", \"full\", \"full\", \"full mouth\", \"futur\", \"give\", \"give\", \"give\", \"grabbi\", \"grabbi\", \"granni\", \"granni smith\", \"granni smith appl\", \"grapefruit orang\", \"great\", \"great\", \"green\", \"green\", \"green\", \"grenach syrah\", \"grill herb\", \"gritti\", \"ground pepper\", \"herb\", \"herb\", \"hint apricot\", \"honeycomb\", \"intermingl\", \"juici\", \"juici\", \"juici\", \"lactic\", \"lake\", \"lanolin\", \"lead\", \"lead\", \"lead nose\", \"lead way\", \"leather flavor\", \"lemon\", \"lemon\", \"lemon-lim acid\", \"lend savori\", \"licoric\", \"licoric\", \"licoric\", \"licoric\", \"light\", \"light\", \"light miner\", \"light textur\", \"lime\", \"lime\", \"linear palat\", \"linger\", \"malbec\", \"malbec\", \"malbec\", \"matur\", \"matur\", \"matur\", \"medium\", \"medium-\", \"medium- full-bodi\", \"melon\", \"menthol\", \"menthol\", \"meringu\", \"merlot\", \"merlot\", \"merlot\", \"merlot cabernet\", \"merlot cabernet franc\", \"merlot cabernet sauvignon\", \"milk\", \"milk chocol\", \"miner element\", \"miner textur\", \"mix\", \"moder long\", \"moder long finish\", \"mouthfeel\", \"much better\", \"need\", \"need\", \"need\", \"need age\", \"need age drink\", \"nice\", \"noir\", \"nose\", \"nose\", \"note\", \"note\", \"note alongsid\", \"note lend\", \"oak\", \"oak\", \"oak\", \"oaki\", \"off-dri\", \"off-dri\", \"off-dri riesl\", \"off-dri riesl 's\", \"offer\", \"offer\", \"offer\", \"offer dri\", \"offer dri black\", \"offer ripe\", \"open\", \"open\", \"open\", \"open aroma\", \"orang\", \"orang\", \"orchard\", \"orchard fruit\", \"palat\", \"palat\", \"palat deliv\", \"palat deliv\", \"palat dole\", \"palat dole juici\", \"palat offer\", \"palat offer\", \"palat offer dri\", \"palat soft\", \"peach\", \"pear\", \"pear\", \"pear white\", \"peel\", \"pepper\", \"pepper\", \"pepper\", \"pepper\", \"perfum\", \"perfum\", \"perfum\", \"petit\", \"petit sirah\", \"petit verdot\", \"pinot\", \"pinot noir\", \"plum\", \"plum\", \"plum\", \"plum\", \"plum black\", \"plum black\", \"plum black\", \"plum black cherri\", \"plum blackberri\", \"plum cherri flavor\", \"plum currant\", \"plum flavor finish\", \"plum raspberri\", \"plum raspberri\", \"plum wild\", \"polish tannin\", \"polish tannin\", \"potenti\", \"potenti\", \"press appl\", \"press appl pear\", \"proportion\", \"prune\", \"prune\", \"quench\", \"quit\", \"raisin\", \"raisin\", \"raisin\", \"raspberri\", \"raspberri\", \"raspberri aroma\", \"raspberri plum\", \"raspberri plum\", \"raspberri plum flavor\", \"readi\", \"readi\", \"readi drink\", \"readi drink\", \"red\", \"red\", \"red\", \"red berri fruit\", \"resini\", \"resini\", \"resini oak\", \"rich\", \"rich\", \"rich\", \"riesl\", \"riesl\", \"riesl 's\", \"riesl palat\", \"ripe\", \"ripe\", \"ripe\", \"ripe berri flavor\", \"ripe cherri\", \"ripe full\", \"ripe wine\", \"roast\", \"roast\", \"roast coffe\", \"roast coffe bean\", \"rubberi\", \"sage\", \"sage\", \"sauci\", \"sauvignon\", \"sauvignon\", \"sauvignon\", \"sauvignon merlot\", \"scorch\", \"scorch earth\", \"seem\", \"show\", \"show\", \"show\", \"show bright\", \"sirah\", \"slight\", \"smack\", \"smith\", \"smith appl\", \"smoke\", \"soft\", \"soft\", \"soft\", \"soft light\", \"spent month\", \"spice\", \"spice\", \"spice\", \"spice tomato\", \"spring flower\", \"stew\", \"sticki\", \"still\", \"still\", \"still\", \"still young\", \"still young\", \"stone\", \"structur\", \"structur\", \"structur\", \"sweet\", \"sweet\", \"sweet tannin\", \"syrah\", \"syrah\", \"syrupi\", \"tangerin acid\", \"tangerin flavor\", \"tannin\", \"tannin\", \"tannin\", \"tannin\", \"tannin drink\", \"tannin drink\", \"tannin drink\", \"tannin leav\", \"tart\", \"tast\", \"tast\", \"textur\", \"textur\", \"toast\", \"toast\", \"toast\", \"tone\", \"uncompl\", \"underbrush\", \"verd\", \"verdot\", \"vinho\", \"vinho verd\", \"vivaci\", \"well\", \"well\", \"whiff\", \"whiff\", \"white\", \"white\", \"white\", \"wild cherri\", \"wine\", \"wine\", \"wine\", \"wine drink\", \"wood\", \"wood\", \"wood\", \"wood age\", \"wood-ag\", \"yellow fruit\", \"yet\", \"young\", \"young\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 6, 3, 7, 1, 2, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el4619747385790967321026414\", ldavis_el4619747385790967321026414_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el4619747385790967321026414\", ldavis_el4619747385790967321026414_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el4619747385790967321026414\", ldavis_el4619747385790967321026414_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "4      0.110336  0.060909       1        1  54.285219\n",
       "5      0.220071 -0.083604       2        1  16.428643\n",
       "2     -0.054400  0.216057       3        1  13.128428\n",
       "6     -0.155405 -0.134441       4        1   7.992915\n",
       "0     -0.052752 -0.028044       5        1   3.129000\n",
       "1     -0.037270 -0.017232       6        1   2.665469\n",
       "3     -0.030581 -0.013645       7        1   2.370326, topic_info=      Category        Freq                Term       Total  loglift  logprob\n",
       "term                                                                        \n",
       "3554   Default  166.000000               drink  166.000000  30.0000  30.0000\n",
       "2080   Default   64.000000            cabernet   64.000000  29.0000  29.0000\n",
       "7943   Default  185.000000               palat  185.000000  28.0000  28.0000\n",
       "5090   Default  100.000000              fruiti  100.000000  27.0000  27.0000\n",
       "1682   Default   89.000000               blend   89.000000  26.0000  26.0000\n",
       "831    Default  183.000000               aroma  183.000000  25.0000  25.0000\n",
       "4844   Default  219.000000               fruit  219.000000  24.0000  24.0000\n",
       "2319   Default  150.000000              cherri  150.000000  23.0000  23.0000\n",
       "400    Default   84.000000                 age   84.000000  22.0000  22.0000\n",
       "546    Default   53.000000            alongsid   53.000000  21.0000  21.0000\n",
       "11918  Default  135.000000                wine  135.000000  20.0000  20.0000\n",
       "1615   Default   79.000000          blackberri   79.000000  19.0000  19.0000\n",
       "7683   Default  106.000000               offer  106.000000  18.0000  18.0000\n",
       "2257   Default   69.000000             charact   69.000000  17.0000  17.0000\n",
       "9573   Default   49.000000           sauvignon   49.000000  16.0000  16.0000\n",
       "9239   Default  145.000000                ripe  145.000000  15.0000  15.0000\n",
       "2091   Default   39.000000  cabernet sauvignon   39.000000  14.0000  14.0000\n",
       "6984   Default   41.000000              merlot   41.000000  13.0000  13.0000\n",
       "9128   Default  109.000000                rich  109.000000  12.0000  12.0000\n",
       "201    Default  172.000000                acid  172.000000  11.0000  11.0000\n",
       "8074   Default   48.000000         palat offer   48.000000  10.0000  10.0000\n",
       "1485   Default  144.000000               black  144.000000   9.0000   9.0000\n",
       "11068  Default  106.000000              textur  106.000000   8.0000   8.0000\n",
       "10504  Default   81.000000            structur   81.000000   7.0000   7.0000\n",
       "10799  Default  155.000000              tannin  155.000000   6.0000   6.0000\n",
       "8920   Default   51.000000               readi   51.000000   5.0000   5.0000\n",
       "10703  Default   39.000000               syrah   39.000000   4.0000   4.0000\n",
       "9224   Default   28.000000               riesl   28.000000   3.0000   3.0000\n",
       "5314   Default   78.000000                give   78.000000   2.0000   2.0000\n",
       "8922   Default   44.000000         readi drink   44.000000   1.0000   1.0000\n",
       "...        ...         ...                 ...         ...      ...      ...\n",
       "5138    Topic7    5.370509  fruiti readi drink    6.051093   3.6228  -5.4915\n",
       "3042    Topic7    2.838157        crisp citrus    3.520647   3.5267  -6.1292\n",
       "8520    Topic7    2.682525   plum black cherri    3.365527   3.5153  -6.1856\n",
       "11570   Topic7    2.602885                verd    3.282442   3.5102  -6.2158\n",
       "2796    Topic7    2.553352              common    3.237440   3.5048  -6.2350\n",
       "11639   Topic7    2.473778          vinho verd    3.153115   3.4995  -6.2666\n",
       "11638   Topic7    2.473778               vinho    3.153115   3.4995  -6.2666\n",
       "10057   Topic7    2.389840          soft light    3.073101   3.4907  -6.3012\n",
       "7055    Topic7    1.850682       miner element    2.534104   3.4279  -6.5568\n",
       "5044    Topic7    1.809766  fruit spice flavor    2.491584   3.4224  -6.5792\n",
       "6305    Topic7    1.678961      leather flavor    2.360206   3.4016  -6.6542\n",
       "328     Topic7    1.666258          acid round    2.355451   3.3960  -6.6618\n",
       "9783    Topic7    1.640621         show bright    2.321648   3.3949  -6.6773\n",
       "3131    Topic7    1.558928       currant berri    2.239809   3.3798  -6.7284\n",
       "3282    Topic7    1.522058      delici alreadi    2.206861   3.3706  -6.7523\n",
       "1108    Topic7    1.504621               atlas    2.184955   3.3691  -6.7638\n",
       "1109    Topic7    1.504621          atlas peak    2.184955   3.3691  -6.7638\n",
       "657     Topic7    1.456030           alvarinho    2.137557   3.3582  -6.7967\n",
       "5803    Topic7    1.446268        hint apricot    2.132115   3.3540  -6.8034\n",
       "5486    Topic7    1.414774    grapefruit orang    2.095594   3.3493  -6.8254\n",
       "1584    Topic7    1.354610    black plum black    2.040037   3.3327  -6.8689\n",
       "10694   Topic7    1.334738        sweet tannin    2.017548   3.3290  -6.8836\n",
       "6018    Topic7    1.332092          intermingl    2.013628   3.3290  -6.8856\n",
       "3180    Topic7    1.338579    dark berri fruit    2.023859   3.3287  -6.8808\n",
       "6200    Topic7    1.323708                lake    2.008258   3.3253  -6.8919\n",
       "7223    Topic7    1.320874         much better    2.005433   3.3246  -6.8941\n",
       "9253    Topic7    1.294937   ripe berri flavor    1.981356   3.3168  -6.9139\n",
       "8586    Topic7    1.243385           plum wild    1.927762   3.3036  -6.9545\n",
       "8746    Topic7    1.218229          proportion    1.900380   3.2975  -6.9750\n",
       "8519    Topic7    1.402297          plum black    6.108478   2.2706  -6.8343\n",
       "\n",
       "[374 rows x 6 columns], token_table=       Topic      Freq                  Term\n",
       "term                                        \n",
       "0          1  0.841722                    's\n",
       "0          2  0.133222                    's\n",
       "0          4  0.018167                    's\n",
       "110        2  0.910016              's readi\n",
       "201        1  0.590299                  acid\n",
       "201        2  0.347235                  acid\n",
       "201        3  0.063660                  acid\n",
       "328        7  0.849094            acid round\n",
       "391        1  0.079838             aftertast\n",
       "391        2  0.904826             aftertast\n",
       "395        2  0.919194       aftertast drink\n",
       "400        1  0.320358                   age\n",
       "400        2  0.676312                   age\n",
       "410        2  0.976592             age drink\n",
       "452        2  0.960388              age well\n",
       "546        1  0.093451              alongsid\n",
       "546        3  0.897125              alongsid\n",
       "554        4  0.157524       alongsid bright\n",
       "554        5  0.787622       alongsid bright\n",
       "555        4  0.162605  alongsid bright acid\n",
       "555        5  0.813025  alongsid bright acid\n",
       "650        1  0.235342              although\n",
       "650        2  0.745250              although\n",
       "657        7  0.467824             alvarinho\n",
       "689        1  0.405923                  anis\n",
       "689        3  0.590433                  anis\n",
       "717        2  0.956811              aperitif\n",
       "730        1  0.943038                  appl\n",
       "730        2  0.053888                  appl\n",
       "781        6  0.881083      appl pear flavor\n",
       "...      ...       ...                   ...\n",
       "11241      3  0.359750                 toast\n",
       "11313      1  0.970486                  tone\n",
       "11438      6  0.752852               uncompl\n",
       "11441      3  0.985334            underbrush\n",
       "11570      7  0.913954                  verd\n",
       "11572      4  0.973011                verdot\n",
       "11638      7  0.634293                 vinho\n",
       "11639      7  0.634293            vinho verd\n",
       "11674      6  0.752851                vivaci\n",
       "11745      1  0.481954                  well\n",
       "11745      2  0.512076                  well\n",
       "11803      1  0.343012                 whiff\n",
       "11803      3  0.657440                 whiff\n",
       "11835      1  0.713310                 white\n",
       "11835      2  0.034515                 white\n",
       "11835      3  0.253110                 white\n",
       "11899      3  0.923809           wild cherri\n",
       "11918      1  0.546239                  wine\n",
       "11918      2  0.435515                  wine\n",
       "11918      3  0.022145                  wine\n",
       "11947      2  0.907309            wine drink\n",
       "12031      1  0.234316                  wood\n",
       "12031      2  0.683421                  wood\n",
       "12031      3  0.058579                  wood\n",
       "12032      2  0.983143              wood age\n",
       "12052      2  0.952021               wood-ag\n",
       "12120      2  0.921098          yellow fruit\n",
       "12137      1  0.993132                   yet\n",
       "12150      1  0.276833                 young\n",
       "12150      2  0.704665                 young\n",
       "\n",
       "[496 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 6, 3, 7, 1, 2, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "pyLDAvis.sklearn.prepare(model, X, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we don't only want to see the chart about, we want to be able to effectively read the reviews in each topic, so, we build a dataframe with the original texts and the cluster number and score assigned to it. The score is the proximity of that review with the most revelant words in that cluster, so we filter those with less than 60% relevance because we only want the most focused ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>cluster</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.872462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.567521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.822930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.642081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the top wine from La BÃ©gude, named aft...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.867355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  cluster     score\n",
       "0  This tremendous 100% varietal wine hails from ...        4  0.872462\n",
       "1  Ripe aromas of fig, blackberry and cassis are ...        7  0.567521\n",
       "2  Mac Watson honors the memory of a wine once ma...        4  0.822930\n",
       "3  This spent 20 months in 30% new French oak, an...        4  0.642081\n",
       "4  This is the top wine from La BÃ©gude, named aft...        5  0.867355"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.transform(X)\n",
    "clusters = [ np.argmax(score) for score in result ]\n",
    "scores = [ max(score) for score in result ]\n",
    "\n",
    "df[\"cluster\"] = clusters\n",
    "df[\"score\"] = scores\n",
    "\n",
    "df.loc[(df[\"score\"] < 0.6), \"cluster\"] = K\n",
    "\n",
    "df[[\"description\",\"cluster\",\"score\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we get the main words for each cluster, some examples and the sizes of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rubbery, flavors, raspberry, resiny, saucy, plum\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5f125a49c1bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m ]\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_examples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mcluster_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cluster\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# copied from https://github.com/bmabey/pyLDAvis/blob/master/pyLDAvis/sklearn.py\n",
    "def _get_topic_term_dists(lda_model):\n",
    "    return _row_norm(lda_model.components_)\n",
    "\n",
    "def _row_norm(dists):\n",
    "    # row normalization function required\n",
    "    # for doc_topic_dists and topic_term_dists\n",
    "    return dists / dists.sum(axis=1)[:, None]\n",
    "\n",
    "topic_term_dists = _get_topic_term_dists(model)\n",
    "\n",
    "# sort cluster centers by proximity to centroid\n",
    "order_centroids = topic_term_dists.argsort()[:, ::-1] \n",
    "\n",
    "cluster_words = [\n",
    "    \", \".join([\n",
    "        vocab_frame.loc[terms[ind].split(' ')].values.tolist()[0][0] for ind in order_centroids[i, :6]\n",
    "    ]) for i in range(K)\n",
    "]\n",
    "cluster_words.append(\"Others\")\n",
    "\n",
    "print(cluster_words[0])\n",
    "\n",
    "cluster_examples = [\n",
    "    df[df[\"cluster\"] == i][\"description\"].values.tolist() for i in range(len(cluster_words))\n",
    "]\n",
    "\n",
    "print(cluster_examples[0][0])\n",
    "\n",
    "cluster_sizes = [ len(df[df[\"cluster\"] == i]) for i in range(len(cluster_words)) ]\n",
    "\n",
    "print(cluster_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we print everything for you to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ea52099076f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Top terms per cluster:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "data = { 'text': df[\"text\"].values.tolist() }\n",
    "\n",
    "frame = pd.DataFrame(data, index = [clusters], columns = ['text'])\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "\n",
    "for i in range(len(cluster_sizes)):\n",
    "    print(\"Cluster %d total:\" % i, cluster_sizes[i])\n",
    "    print() #add whitespace\n",
    "    \n",
    "    print(cluster_words[i])\n",
    "    print() #add whitespace\n",
    "    \n",
    "    print(\"Cluster %d examples:\" % i)\n",
    "    for title in cluster_examples[i][:15]:\n",
    "        print('- %s' % title)\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, one problem with Unsupervised Learning of clustering is that you have to choose beforehand the number of clusters that you want, previously, we choose a small number, and maybe creating topics that are actually talking about two different things.\n",
    "\n",
    "On the other hand, if we choose too many topics we might break those topics in smaller ones, but create many one which are actually talking about the same things.\n",
    "\n",
    "We can visualize this effect on the chart, take a look with K = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "K2 = 30\n",
    "\n",
    "model2 = LatentDirichletAllocation(n_components=K2, max_iter=100, random_state=0)\n",
    "model2.fit(X)\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "pyLDAvis.sklearn.prepare(model2, X, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "\n",
    "I only managed to create this notebook thanks to those two awesome tutorials, which I basically copied for this topic modelling work:\n",
    "\n",
    "1. Document Clustering with Python - http://brandonrose.org/clustering\n",
    "2. Modern NLP in Python - https://www.youtube.com/watch?v=6zm9NC9uRkk\n",
    "\n",
    "And thanks for the [@datasciencepython](https://web.telegram.org/#/im?p=@datasciencepython) group in telegram for pointing me in the right direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
